{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline for Quantifying and Mitigating Bias in CelebA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.12.0)\n",
      "Requirement already satisfied: torchvision in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.15.2)\n",
      "Requirement already satisfied: tensorflow in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.13.0)\n",
      "Requirement already satisfied: keras in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (2.13.1)\n",
      "Requirement already satisfied: pandas in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.0.3)\n",
      "Requirement already satisfied: numpy in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.24.3)\n",
      "Requirement already satisfied: matplotlib in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (3.7.2)\n",
      "Requirement already satisfied: scikit-learn in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: tqdm in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (4.65.0)\n",
      "Requirement already satisfied: ftfy in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (6.1.1)\n",
      "Requirement already satisfied: accelerate in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (0.20.3)\n",
      "Requirement already satisfied: scipy in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (1.11.1)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 13)) (4.31.0)\n",
      "Requirement already satisfied: diffusers==0.11.1 in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 15)) (0.11.1)\n",
      "Requirement already satisfied: seaborn in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (0.12.2)\n",
      "Requirement already satisfied: tensorflow_hub in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 17)) (0.14.0)\n",
      "Requirement already satisfied: utils in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 18)) (1.0.1)\n",
      "Requirement already satisfied: nltk in /home/ec221049/.local/lib/python3.9/site-packages (from -r requirements.txt (line 20)) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec221049/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: requests in /home/ec221049/.local/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec221049/.local/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 2)) (9.5.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (3.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (0.32.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (23.5.26)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (1.56.0)\n",
      "Requirement already satisfied: setuptools in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (68.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (2.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (16.0.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (4.23.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 3)) (2.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ec221049/.local/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 5)) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec221049/.local/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 5)) (2023.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /home/ec221049/.local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (6.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/ec221049/.local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec221049/.local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec221049/.local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec221049/.local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec221049/.local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec221049/.local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec221049/.local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/site-packages (from ftfy->-r requirements.txt (line 10)) (0.2.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib64/python3.9/site-packages (from accelerate->-r requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib64/python3.9/site-packages (from accelerate->-r requirements.txt (line 11)) (5.9.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec221049/.local/lib/python3.9/site-packages (from transformers>=4.25.1->-r requirements.txt (line 13)) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec221049/.local/lib/python3.9/site-packages (from transformers>=4.25.1->-r requirements.txt (line 13)) (2023.6.3)\n",
      "Requirement already satisfied: filelock in /home/ec221049/.local/lib/python3.9/site-packages (from transformers>=4.25.1->-r requirements.txt (line 13)) (3.12.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ec221049/.local/lib/python3.9/site-packages (from transformers>=4.25.1->-r requirements.txt (line 13)) (0.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/ec221049/.local/lib/python3.9/site-packages (from transformers>=4.25.1->-r requirements.txt (line 13)) (0.15.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.9/site-packages (from diffusers==0.11.1->-r requirements.txt (line 15)) (6.6.0)\n",
      "Requirement already satisfied: click in /home/ec221049/.local/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 20)) (8.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec221049/.local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec221049/.local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec221049/.local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.26.16)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ec221049/.local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 3)) (0.40.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (2.3.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (3.4.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ec221049/.local/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (2.22.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.9/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib->-r requirements.txt (line 7)) (3.15.0)\n",
      "Requirement already satisfied: fsspec in /home/ec221049/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.25.1->-r requirements.txt (line 13)) (2023.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec221049/.local/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib64/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec221049/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec221049/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec221049/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (0.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec221049/.local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (3.2.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec221049/.local/lib/python3.9/site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 3)) (0.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 21:50:04.583701: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-24 21:50:04.625520: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 21:50:05.265914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from cuda_available import check_cuda_availaibility\n",
    "from quantify_bias import compute_metrics, count_attributes\n",
    "from read_data_image_files import read_data_file, preprocess_data, read_image_data, image_standardization\n",
    "from multilabel_classifier import train_val_test_split, build_model, refit_model, evaluate_model, make_predictions, analyze_failed_samples, save_over_sampling_data\n",
    "from diffusion_model import define_stable_diffusion_model, generate_images_situational_prompt, generate_images_static_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver (to run data pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_data_augmentation():\n",
    "    print(\"Prior to data augmention\")\n",
    "    \n",
    "    ## pre-data augmentation\n",
    "    directory = 'Data'\n",
    "    file_path = 'protected_attributes_post_eda.csv'\n",
    "    data = read_data_file(directory, file_path)\n",
    "    print(\"Original data samples\")\n",
    "    print(data.head())\n",
    "    \n",
    "    print(\"Distribution of data\")\n",
    "    count_attributes(data)\n",
    "    \n",
    "    print(\"Bias quantification\")\n",
    "    print(compute_metrics(data))\n",
    "\n",
    "    data_encoded = preprocess_data(data)\n",
    "    \n",
    "    file_path = 'celebA/img_align_celeba/img_align_celeba/'\n",
    "    X, y = read_image_data(data_encoded, directory, file_path)\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X, y)\n",
    "\n",
    "    model_name = 'vggnet'\n",
    "    model = build_model(model_name, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    test_accuracy, precision, auc = evaluate_model(model, X_test, y_test)\n",
    "    failed_samples, attribute_accuracies, attribute_precisions = make_predictions (model, X_test, y_test, data_encoded)\n",
    "    print(\"Accuracy by attribute:\", attribute_accuracies)\n",
    "    \n",
    "    data_file = 'non-protected_attributes_post_eda.csv'\n",
    "    non_protected_data = read_data_file(directory, data_file)\n",
    "\n",
    "    # Perform an inner join based on the 'image_id' column\n",
    "    merged_df_all_attributes = pd.merge(data, non_protected_data, on='image_id')\n",
    "\n",
    "    missclassified_samples = analyze_failed_samples (failed_samples, merged_df_all_attributes)\n",
    "\n",
    "    directory = 'Data Generation-Stable Diffusion'\n",
    "    save_over_sampling_data(model_name, directory, missclassified_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(prompt_type):\n",
    "    model_name = 'vggnet'\n",
    "    directory = 'Data Generation-Stable Diffusion'\n",
    "    file_path = f\"miss_classified_image_samples_{model_name}.csv\"\n",
    "    # Read the CSV file\n",
    "    data_miss_classified = read_data_file(directory, file_path)\n",
    "    \n",
    "    try:\n",
    "        pipe = define_stable_diffusion_model()\n",
    "        print(pipe)\n",
    "        directory = 'Data'\n",
    "        file_path = f'images_generated_stable_diffusion_{model_name}.csv'\n",
    "        image_path = f'synthetic_data_augmentation_celebA_{model_name}'\n",
    "        if(prompt_type == \"situational\"):\n",
    "            generate_images_situational_prompt(data_miss_classified, pipe, directory, image_path, file_path)\n",
    "        else:\n",
    "            generate_images_static_prompt(data_miss_classified, pipe, directory, image_path, file_path)\n",
    "\n",
    "\n",
    "    except MemoryError as mem_error:\n",
    "        print(\"Memory error:\", mem_error)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_data_augmentation():\n",
    "    print(\"Post data augmention\")\n",
    "    \n",
    "    ## post-data augmentation\n",
    "    directory = 'Data'\n",
    "    file_path = 'protected_attributes_post_eda.csv'\n",
    "    data = read_data_file(directory, file_path)\n",
    "    data_encoded = preprocess_data(data)\n",
    "    \n",
    "    model_name = 'vggnet'\n",
    "    file_path = f'images_generated_stable_diffusion_{model_name}.csv'\n",
    "    data1 = read_data_file(directory, file_path)\n",
    "    data1.columns = [\"image_id\", \"race\", \"gender\", \"emotion\"]\n",
    "\n",
    "    data = pd.concat([data, data1], ignore_index=True)\n",
    "    data_encoded = preprocess_data(data)\n",
    "\n",
    "\n",
    "    file_path = 'synthetic_data_augmentation_celebA_vgg_16/'\n",
    "    X_generated, y_generated = read_image_data(data_encoded, directory, file_path)\n",
    "\n",
    "    model = refit_model(X_generated, y_generated, X_val, y_val)\n",
    "    test_accuracy, precision, auc = evaluate_model(model, X_test, y_test)\n",
    "    failed_samples, attribute_accuracies, attribute_precisions = make_predictions (model, X_test, y_test, data_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior to data augmention\n",
      "Original data samples\n",
      "     image_id             race gender emotion\n",
      "0  009680.jpg  latino hispanic  Woman   happy\n",
      "1  009028.jpg            white  Woman   happy\n",
      "2  007702.jpg            white  Woman     sad\n",
      "3  009681.jpg            white    Man   happy\n",
      "4  010355.jpg            white  Woman     sad\n",
      "Distribution of data\n",
      "Categories and counts for race:\n",
      "race\n",
      "white              7027\n",
      "asian               968\n",
      "latino hispanic     953\n",
      "black               724\n",
      "middle eastern      584\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Categories and counts for gender:\n",
      "gender\n",
      "Woman    5959\n",
      "Man      4297\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Categories and counts for emotion:\n",
      "emotion\n",
      "happy       4551\n",
      "neutral     3120\n",
      "sad         1183\n",
      "fear         760\n",
      "angry        471\n",
      "surprise     140\n",
      "disgust       31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Bias quantification\n",
      "  Attribute  Shannon Diversity  Shannon Evenness  Simpson Diversity  \\\n",
      "0      race           1.052934          0.654225           2.019335   \n",
      "1    gender           0.679959          0.980973           1.948823   \n",
      "2   emotion           1.382167          0.710293           3.220081   \n",
      "\n",
      "   Simpson Evenness  \n",
      "0          0.403867  \n",
      "1          0.974411  \n",
      "2          0.460012  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10256/10256 [00:12<00:00, 841.81it/s]\n",
      "2023-08-24 21:50:27.121782: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 251s 2s/step - loss: 0.3256 - binary_accuracy: 0.8312 - precision: 0.9276 - auc: 0.8407 - val_loss: 0.2714 - val_binary_accuracy: 0.8407 - val_precision: 0.9674 - val_auc: 0.8576\n",
      "13/13 [==============================] - 11s 866ms/step - loss: 0.2803 - binary_accuracy: 0.8394 - precision: 0.9725 - auc: 0.8523\n",
      "\n",
      "Test Accuracy: 0.8394160866737366\n",
      "\n",
      "Test loss: 0.280304878950119\n",
      "\n",
      "Precision: 0.9724770784378052\n",
      "\n",
      "Auc: 0.8522663116455078\n",
      "13/13 [==============================] - 11s 865ms/step\n",
      "Accuracy by attribute: {'Attribute_image_id': 89.78102189781022, 'Attribute_race_asian': 92.45742092457421, 'Attribute_race_black': 90.51094890510949, 'Attribute_race_latino hispanic': 94.40389294403893, 'Attribute_race_middle eastern': 35.523114355231144, 'Attribute_race_white': 88.07785888077859, 'Attribute_gender_Man': 84.42822384428223, 'Attribute_gender_Woman': 95.62043795620438, 'Attribute_emotion_angry': 99.7566909975669, 'Attribute_emotion_disgust': 92.45742092457421, 'Attribute_emotion_fear': 58.63746958637469, 'Attribute_emotion_happy': 66.18004866180048, 'Attribute_emotion_neutral': 88.32116788321169, 'Attribute_emotion_sad': 99.02676399026764}\n"
     ]
    }
   ],
   "source": [
    "pre_data_augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"situational\" # can take values either static or situational\n",
    "generate_samples(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data_augmentation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
